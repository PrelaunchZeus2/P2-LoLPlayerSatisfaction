{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is about Response Tokenization and Generating Wordclouds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization is the Process of taking words or phrases and dividing them into smaller parts for processing. It is important to note that tokens are not individual words, they instead are chunks of words, think about analyzing the following sentences only examining each word. \"The Trophy Would Not Fit Into The Case Because It Was Too Small.\"\n",
    "and \"The Trophy Would Not Fit Into The Case Because It Was Too Big.\" notice how changing the word from big to small changes what object the pronoun \"it\" refers to in the sentence. The meaning of the word it is derived from the adjective. This is an example of why processing language needs to be done in chunks instead of by individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Statements\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
